# Ollama Web API ëª…ì„¸ì„œ

## ğŸ“Œ ê°œìš”

Ollama ê¸°ë°˜ AI ì±—ë´‡ì„ ìœ„í•œ REST APIì…ë‹ˆë‹¤. ì™¸ë¶€ì—ì„œ HTTP ìš”ì²­ì„ í†µí•´ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**Base URL**: `http://172.17.3.220:5000`

---

## ğŸ”§ ì—”ë“œí¬ì¸íŠ¸

### 1. Health Check

ì„œë²„ ë° Ollama ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

**Endpoint**: `GET /api/health`

#### ìš”ì²­ ì˜ˆì‹œ
```bash
curl http://172.17.3.220:5000/api/health
```

#### ì‘ë‹µ ì˜ˆì‹œ
```json
{
  "status": "ok",
  "ollama_status": "connected",
  "api_version": "1.0.0"
}
```

#### ì‘ë‹µ í•„ë“œ
| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `status` | string | API ì„œë²„ ìƒíƒœ (`ok` or `error`) |
| `ollama_status` | string | Ollama ì—°ê²° ìƒíƒœ (`connected` or `disconnected`) |
| `api_version` | string | API ë²„ì „ |

---

### 2. ëª¨ë¸ ëª©ë¡ ì¡°íšŒ

ì„¤ì¹˜ëœ AI ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

**Endpoint**: `GET /api/models`

#### ìš”ì²­ ì˜ˆì‹œ
```bash
curl http://172.17.3.220:5000/api/models
```

#### ì‘ë‹µ ì˜ˆì‹œ
```json
{
  "success": true,
  "models": [
    "llama3.1:70b",
    "llama3.1:8b",
    "qwen2.5:72b"
  ],
  "count": 3
}
```

#### ì‘ë‹µ í•„ë“œ
| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `success` | boolean | ìš”ì²­ ì„±ê³µ ì—¬ë¶€ |
| `models` | array | ì„¤ì¹˜ëœ ëª¨ë¸ ì´ë¦„ ëª©ë¡ |
| `count` | integer | ëª¨ë¸ ê°œìˆ˜ |

---

### 3. ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ (ì¼ë°˜)

AIì—ê²Œ ì§ˆë¬¸ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.

**Endpoint**: `POST /api/chat`

#### ìš”ì²­ ë³¸ë¬¸
```json
{
  "message": "ì•ˆë…•í•˜ì„¸ìš”! RTX 5090ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
  "model": "llama3.1:70b",
  "stream": false
}
```

#### ìš”ì²­ í•„ë“œ
| í•„ë“œ | íƒ€ì… | í•„ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|------|------|--------|------|
| `message` | string | âœ… | - | ì‚¬ìš©ì ì§ˆë¬¸ |
| `model` | string | âŒ | `llama3.1:70b` | ì‚¬ìš©í•  AI ëª¨ë¸ |
| `stream` | boolean | âŒ | `false` | ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€ |

#### ìš”ì²­ ì˜ˆì‹œ
```bash
curl -X POST http://172.17.3.220:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is artificial intelligence?",
    "model": "llama3.1:70b"
  }'
```

#### ì‘ë‹µ ì˜ˆì‹œ
```json
{
  "success": true,
  "response": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines...",
  "model": "llama3.1:70b",
  "done": true,
  "context": [123, 456, 789, ...]
}
```

#### ì‘ë‹µ í•„ë“œ
| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `success` | boolean | ìš”ì²­ ì„±ê³µ ì—¬ë¶€ |
| `response` | string | AIì˜ ì‘ë‹µ í…ìŠ¤íŠ¸ |
| `model` | string | ì‚¬ìš©ëœ ëª¨ë¸ ì´ë¦„ |
| `done` | boolean | ì‘ë‹µ ì™„ë£Œ ì—¬ë¶€ |
| `context` | array | ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (í† í° ID) |

---

### 4. ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ (ìŠ¤íŠ¸ë¦¬ë°)

AI ì‘ë‹µì„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.

**Endpoint**: `POST /api/chat/stream`

#### ìš”ì²­ ë³¸ë¬¸
```json
{
  "message": "Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ êµ¬í˜„í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
  "model": "llama3.1:70b"
}
```

#### ìš”ì²­ ì˜ˆì‹œ
```bash
curl -X POST http://172.17.3.220:5000/api/chat/stream \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Tell me a story",
    "model": "llama3.1:70b"
  }'
```

#### ì‘ë‹µ í˜•ì‹
ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (NDJSON - Newline Delimited JSON)

```json
{"response":"Once","done":false}
{"response":" upon","done":false}
{"response":" a","done":false}
{"response":" time","done":false}
...
{"response":"","done":true,"context":[123,456,...]}
```

---

## âš ï¸ ì—ëŸ¬ ì‘ë‹µ

ëª¨ë“  ì—ëŸ¬ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤:

```json
{
  "success": false,
  "error": "ì—ëŸ¬ ë©”ì‹œì§€"
}
```

### HTTP ìƒíƒœ ì½”ë“œ
| ì½”ë“œ | ì˜ë¯¸ | ì„¤ëª… |
|------|------|------|
| `200` | OK | ìš”ì²­ ì„±ê³µ |
| `400` | Bad Request | ì˜ëª»ëœ ìš”ì²­ (í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ë“±) |
| `404` | Not Found | ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸ |
| `500` | Internal Server Error | ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ |
| `504` | Gateway Timeout | ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (5ë¶„) |

---

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### Python
```python
import requests

# ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡
response = requests.post(
    "http://172.17.3.220:5000/api/chat",
    json={
        "message": "ì•ˆë…•í•˜ì„¸ìš”!",
        "model": "llama3.1:70b"
    }
)

data = response.json()
if data["success"]:
    print(data["response"])
else:
    print(f"Error: {data['error']}")
```

### JavaScript (Node.js)
```javascript
const axios = require('axios');

async function chat(message) {
  try {
    const response = await axios.post('http://172.17.3.220:5000/api/chat', {
      message: message,
      model: 'llama3.1:70b'
    });

    if (response.data.success) {
      console.log(response.data.response);
    }
  } catch (error) {
    console.error('Error:', error.message);
  }
}

chat('Hello, AI!');
```

### cURL
```bash
# ê°„ë‹¨í•œ ì§ˆë¬¸
curl -X POST http://172.17.3.220:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"What is 2+2?"}'

# ëª¨ë¸ ì§€ì •
curl -X POST http://172.17.3.220:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explain quantum computing",
    "model": "qwen2.5:72b"
  }'
```

### PowerShell
```powershell
$body = @{
    message = "ì•ˆë…•í•˜ì„¸ìš”!"
    model = "llama3.1:70b"
} | ConvertTo-Json

$response = Invoke-RestMethod `
    -Uri "http://172.17.3.220:5000/api/chat" `
    -Method Post `
    -Body $body `
    -ContentType "application/json"

Write-Host $response.response
```

---

## ğŸš€ ì„œë²„ ì‹¤í–‰

### ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)
```bash
pip install flask flask-cors requests
```

### ì‹¤í–‰
```bash
cd /home/ubuntu/workspace/seongwook_ha/ollama-web
python3 api_server.py
```

ë˜ëŠ”

```bash
./start.sh
```

### í¬íŠ¸ ì„¤ì •
- API ì„œë²„: `5000`
- ì›¹ ì¸í„°í˜ì´ìŠ¤: `8080`
- Ollama: `11434`

---

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **ì¸ì¦ ì—†ìŒ**: í˜„ì¬ ë²„ì „ì€ ì¸ì¦ì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” API í‚¤ ë˜ëŠ” JWT ì¸ì¦ì„ ì¶”ê°€í•˜ì„¸ìš”.
2. **Rate Limiting**: ê³¼ë„í•œ ìš”ì²­ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Rate Limitingì„ êµ¬í˜„í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
3. **HTTPS**: í”„ë¡œë•ì…˜ì—ì„œëŠ” HTTPSë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
4. **ë°©í™”ë²½**: í•„ìš”í•œ IPë§Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ë°©í™”ë²½ ê·œì¹™ì„ ì„¤ì •í•˜ì„¸ìš”.

---

## ğŸ“Š ì‘ë‹µ ì‹œê°„

ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì‘ë‹µ ì‹œê°„ì´ ë‹¤ë¦…ë‹ˆë‹¤:

| ëª¨ë¸ | í‰ê·  ì‘ë‹µ ì‹œê°„ | ê¶Œì¥ ìš©ë„ |
|------|---------------|----------|
| `llama3.1:8b` | 1-3ì´ˆ | ë¹ ë¥¸ ì‘ë‹µ í•„ìš” ì‹œ |
| `llama3.1:70b` | 5-15ì´ˆ | ì¼ë°˜ì ì¸ ëŒ€í™” |
| `qwen2.5:72b` | 5-15ì´ˆ | í•œêµ­ì–´ íŠ¹í™” |
| `llama3.1:405b` | 30-60ì´ˆ | ìµœê³  í’ˆì§ˆ í•„ìš” ì‹œ |

*RTX 5090 ê¸°ì¤€

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### 1. "Ollama connection error"
```bash
# Ollama ì„œë¹„ìŠ¤ í™•ì¸
systemctl status ollama

# Ollama ì¬ì‹œì‘
sudo systemctl restart ollama
```

### 2. "Connection refused"
```bash
# í¬íŠ¸ ì‚¬ìš© í™•ì¸
netstat -tlnp | grep 5000

# ë°©í™”ë²½ í™•ì¸
sudo ufw status
sudo ufw allow 5000/tcp
```

### 3. "Request timeout"
- ëŒ€í˜• ëª¨ë¸(405B)ì€ ì‘ë‹µ ì‹œê°„ì´ ê¹ë‹ˆë‹¤.
- ë” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ íƒ€ì„ì•„ì›ƒ ì‹œê°„ì„ ëŠ˜ë¦¬ì„¸ìš”.

---

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”:
```bash
tail -f /tmp/ollama.log
```

---

**Version**: 1.0.0
**Last Updated**: 2026-02-23
**Author**: Ollama Web API Team
